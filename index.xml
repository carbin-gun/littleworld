<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Little World</title>
    <link>http://littleworld.me/</link>
    <description>Recent content on Little World</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 16 Oct 2016 14:07:41 +0800</lastBuildDate>
    <atom:link href="http://littleworld.me/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Redis Lock</title>
      <link>http://littleworld.me/2016/10/16/redis-lock</link>
      <pubDate>Sun, 16 Oct 2016 14:07:41 +0800</pubDate>
      
      <guid>http://littleworld.me/2016/10/16/redis-lock</guid>
      <description>

&lt;p&gt;simple distributed lock on redis and how to improve it with the redlock algorithm.the pros and cons the redlock algorithm.&lt;/p&gt;

&lt;p&gt;+++
title = &amp;ldquo;redis string operations&amp;rdquo;
date = &amp;ldquo;2016-10-14T16:20:41+08:00&amp;rdquo;
tags = [&amp;ldquo;redis&amp;rdquo;,&amp;ldquo;string&amp;rdquo;,&amp;ldquo;rate limit&amp;rdquo;]
categories = [&amp;ldquo;programming&amp;rdquo;,&amp;ldquo;cache&amp;rdquo;]
menu = &amp;ldquo;&amp;rdquo;
banner = &amp;ldquo;banners/redis.jpg&amp;rdquo;
+++
Notes about the commands of Redis String operations.Especially some scenarios that would be much useful.&lt;/p&gt;

&lt;h1 id=&#34;redis-lock&#34;&gt;Redis Lock&lt;/h1&gt;

&lt;h2 id=&#34;introduction-usage&#34;&gt;Introduction/Usage&lt;/h2&gt;

&lt;p&gt;In distributed system,use distributed lock to guarantee serial operation for avoiding race-condition conflicts.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Simple Solution&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;set a key value only when the key is not existed.In case of the client crash,the lock on the key will not be removed,we add expire time on the key .the whole operation can be like the following.
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt; SET resource_name my_random_value NX PX 30000
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The above command should guarantee the &lt;strong&gt;value should be unique among all the requests&lt;/strong&gt;,because there can be senarios,like :a client may acquire the lock, get blocked in some operation for longer than the lock validity time (the time at which the key will expire), and later remove the lock, that was already acquired by some other client.so the lock can&amp;rsquo;t be just removed by the key. It should be done like this lua script:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-lua&#34;&gt;if redis.call(&amp;quot;get&amp;quot;,KEYS[1]) == ARGV[1] then
return redis.call(&amp;quot;del&amp;quot;,KEYS[1])
else
    return 0
end
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;More Complicated Solution&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The Simple solution is not ok under the condition that:

&lt;ol&gt;
&lt;li&gt;the redis node crashed,the slave hasn&amp;rsquo;t synced from the master to get the lock.the above solution will fail.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;The redis official site gives an algorithm called &lt;code&gt;The Redlock algorithm&lt;/code&gt; to provide a more  robust distributed-lock feature.&lt;/li&gt;
&lt;li&gt;the doc and implementations can be found here &lt;a href=&#34;http://redis.io/topics/distlock&#34;&gt;the redlock algorithm&lt;/a&gt;.
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pros and Cons on the Redlock algorithm
what are the distributed locks for:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;: Taking a lock saves you from unnecessarily doing the same work twice (e.g. some expensive computation). If the lock fails and two nodes end up doing the same piece of work, the result is a minor increase in cost (you end up paying 5 cents more to AWS than you otherwise would have) or a minor inconvenience (e.g. a user ends up getting the same email notification twice).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Correctness&lt;/strong&gt;: Taking a lock prevents concurrent processes from stepping on each others’ toes and messing up the state of your system. If the lock fails and two nodes concurrently work on the same piece of data, the result is a corrupted file, data loss, permanent inconsistency, the wrong dose of a drug administered to a patient, or some other serious problem.&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;The redlock algorithm&lt;/code&gt; solves the sigal node problems ,but brings up more problems which are existed natuarally  in the distributed system.But the redlock algorithm did not solve them all.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;conclusion&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Redis may not be a good option for distributed lock if you want it for its correctness.but for efficiency ,it&amp;rsquo;s good enough.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Check the total pros and cons from the below address.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html&#34;&gt;How to do distributed locking&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://antirez.com/news/101&#34;&gt;Is Redlock Safe&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>redis string operations</title>
      <link>http://littleworld.me/2016/10/14/redis-string-operations</link>
      <pubDate>Fri, 14 Oct 2016 16:20:41 +0800</pubDate>
      
      <guid>http://littleworld.me/2016/10/14/redis-string-operations</guid>
      <description>

&lt;p&gt;Notes about the commands of Redis String operations.Especially some scenarios that would be much useful.&lt;/p&gt;

&lt;h2 id=&#34;redis&#34;&gt;Redis&lt;/h2&gt;

&lt;h2 id=&#34;string-operation&#34;&gt;String Operation.&lt;/h2&gt;

&lt;h2 id=&#34;set&#34;&gt;SET&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法: &lt;code&gt;SET key value [EX seconds] [PX milliseconds] [NX|XX]&lt;/code&gt;,整个set系列里功能最完整的一个命令,&lt;code&gt;setnx&lt;/code&gt;,&lt;code&gt;setex&lt;/code&gt;能完成的事情，都可以用&lt;code&gt;set&lt;/code&gt;完成.&lt;/li&gt;
&lt;li&gt;对于某个原本带有生存时间（TTL）的键来说， 当 SET 命令成功在这个键上执行时， 这个键原有的 TTL 将被清除。&lt;/li&gt;
&lt;li&gt;即: &lt;strong&gt;set是一个覆盖式写.如果写发生，则对于value和ttl都是覆盖式的&lt;/strong&gt;.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;解释:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;key word&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;EX second&lt;/td&gt;
&lt;td&gt;设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;PX millisecond&lt;/td&gt;
&lt;td&gt;设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;NX&lt;/td&gt;
&lt;td&gt;只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value .&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;XX&lt;/td&gt;
&lt;td&gt;只在键已经存在时，才对键进行设置操作.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;getbit-setbit-bitcount&#34;&gt;GETBIT/SETBIT/BITCOUNT&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Redis&lt;/code&gt;针对位做操作的支持.&lt;/li&gt;
&lt;li&gt;用法 : &lt;code&gt;setbit key offset 1&lt;/code&gt;,设置某个key的某个offset为1(当然也可以设置为0,不过因为默认为0.为0的时候不去管理就好了。不过如果是设置为1设置错了或者要重新从1变为0,就可以设置).&lt;code&gt;getbit key offset&lt;/code&gt;,获取key的offset位置的bit值是0还是1.&lt;code&gt;bitcount key [start] [end]&lt;/code&gt;,给出key在指定区间(不指定区间则表示所有),所有bit值为1的个数.&lt;/li&gt;
&lt;li&gt;模式:

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Bitmap&lt;/strong&gt; 对于一些特定类型的计算非常有效。假设现在我们希望记录自己网站上的用户的&lt;strong&gt;上线频率&lt;/strong&gt;，比如说，计算用户 A 上线了多少天，用户 B 上线了多少天，诸如此类，以此作为数据，从而决定让哪些用户参加 beta 测试等活动 —— 这个模式可以使用 SETBIT 和 BITCOUNT 来实现。&lt;/li&gt;
&lt;li&gt;以此想到了一个场景,比如每个用户每天只能操作一次的情况.每个月最多31号.维护一个31bit长的redis key即可.每天如果操作了就是1.没操作就是0.每个月做一次数据的删除(keys+del,此时keys跟del非原子,要保证原子性还是得用&lt;code&gt;redis+lua&lt;/code&gt;),不然会可能有人在删除的间隙操作了,这时候由于整个删除机制被干掉了.BUT更好的方式是每天重置之前天的数据就好了.这样所有数据重置的时候没有写入,也就不需要考虑资源征用的问题(&lt;strong&gt;通过避免并发才是最好的性能&lt;/strong&gt;).但是这里最重要的是,一定周期之后要获得用户每天的是否操作的数据,如果不获得则仅仅就用（setnx来做就行,这样每天的数据是一个key.这个key第二次就会由于存在而setnx会返回失败).&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;BIT操作的性能&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;前面的上线次数统计例子，即使运行 10 年，占用的空间也只是每个用户 10*365 比特位(bit)，也即是每个用户 456 字节。对于这种大小的数据来说， BITCOUNT 的处理速度就像 GET 和 INCR 这种 O(1) 复杂度的操作一样快。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果你的 bitmap 数据非常大，那么可以考虑使用以下两种方法：&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;将一个大的 bitmap 分散到不同的 key 中，作为小的 bitmap 来处理。使用 Lua 脚本可以很方便地完成这一工作。
使用 BITCOUNT 的 start 和 end 参数，每次只对所需的部分位进行计算，将位的累积工作(accumulating)放到客户端进行，并且对结果进行缓存 (caching).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;getset&#34;&gt;GETSET&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法 &lt;code&gt;getset key value&lt;/code&gt;,给key设置一个新值,并返回key的旧值(没有旧值返回nil).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;set&lt;/code&gt;命令成功返回的是OK.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;模式:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;GETSET 可以和 INCR 组合使用，实现一个有原子性(atomic)复位操作的计数器(counter)。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;举例来说，每次当某个事件发生时，进程可能对一个名为 mycount 的 key 调用 INCR 操作，通常我们还要在一个原子时间内同时完成获得计数器的值和将计数器值复位为 0 两个操作.实际上在实际过程中,需要在&lt;code&gt;incr&lt;/code&gt;之后还要对&lt;code&gt;incr&lt;/code&gt;的操作结果做判断,然后再复位为0.这时候&lt;code&gt;incr&lt;/code&gt;和&lt;code&gt;getset&lt;/code&gt;之间已经有时间消耗，不再是原子的.这在高并发场景如果不能接受.这时候应该考虑&lt;code&gt;redis+lua&lt;/code&gt;的实现.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redis&amp;gt; INCR mycount
(integer) 11

redis&amp;gt; GETSET mycount 0  # 一个原子内完成 GET mycount 和 SET mycount 0 操作
&amp;quot;11&amp;quot;

redis&amp;gt; GET mycount       # 计数器被重置
&amp;quot;0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;mget&#34;&gt;MGET&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法 &lt;code&gt;mget key1 [key2] [key3...]&lt;/code&gt;,一次返回多个key的值,返回值的顺序和key值的顺序一致.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果某个key不存在,该key对应返回的值是nil,该命令永不失败.&lt;/p&gt;

&lt;h2 id=&#34;mset&#34;&gt;MSET&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用法: &lt;code&gt;MSET key value [key value ...]&lt;/code&gt;,一次设置多个key的值.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果某个给定 key 已经存在，那么 &lt;strong&gt;MSET 会用新值覆盖原来的旧值&lt;/strong&gt;，如果这不是你所希望的效果，请考虑使用 &lt;strong&gt;MSETNX 命令：它只会在所有给定 key 都不存在的情况下进行设置操作s&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;MSET是一个原子性(atomic)操作&lt;/strong&gt;，所有给定 key 都会在同一时间内被设置，某些给定 key 被更新而另一些给定 key 没有改变的情况，不可能发生.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;命令总是返回OK,因为mset不会失败&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;msetnx&#34;&gt;MSETNX&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法同mset,但是不同的是仅仅在所有key不存在的时候才设置值.如果有任何一个key已经存在,整个msetnx是不执行的.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MSETNX是一个原子性(atomic)操作&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;setex&#34;&gt;SETEX&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法: &lt;code&gt;setex key seconds value&lt;/code&gt;,含义: set expire.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;最终结果等价于&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;set key value
expire key seconds
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;与以上命令的区别:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;setex是一个原子操作,关联key和value的同时设置了超时时间.但是一旦用set+expire组合来实现的时候,至少是两个命令.这时候中间至少有 &lt;code&gt;set返回+expire命令发送的时间间隔&lt;/code&gt;,如果set和expire在发送到redis之间有别的操作,间隔时间就会更长.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;psetex&#34;&gt;PSETEX&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法: &lt;code&gt;psetex key milliseconds value&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;这个命令和 SETEX 命令相似，但&lt;strong&gt;它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;setnx&#34;&gt;SETNX&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法: &lt;code&gt;setnx key value&lt;/code&gt;,含义:set if not exist.&lt;/li&gt;
&lt;li&gt;注意: &lt;strong&gt;setnx不支持设置超时时间&lt;/strong&gt;，仅仅能给key设置一个不带超时的值.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;模式: 可以用在只能操作一次的场景.比如 每天只能签到一次.这时候第二次来接口重复性验证就可以redis直接完成(速度更快).每次操作如果不是永远有效.往往还需要设置一个expire的时间.这时候如果用&lt;code&gt;setnx+expire&lt;/code&gt;不能保证原子性.则需要用&lt;code&gt;set+NX&lt;/code&gt;命令来实现&lt;/p&gt;

&lt;h2 id=&#34;setrange&#34;&gt;SETRANGE&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用法:&lt;code&gt;setrange key offset value&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;最简总结:&lt;strong&gt;override从offset开始的数据,如果offset之前无内容用&amp;rdquo;\x00&amp;rdquo;填充,key不存在,相当于整个内容最初就是空的&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;SETRANGE 命令会确保字符串足够长以便将 value 设置在指定的偏移量上，如果给定 key 原来储存的字符串长度比偏移量小(比如字符串只有 5 个字符长，但你设置的 offset 是 10 )，那么原字符和偏移量之间的空白将用零字节(zerobytes, &amp;ldquo;\x00&amp;rdquo; )来填充。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;getrange&#34;&gt;GETRANGE&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法: &lt;code&gt;getrange key start end&lt;/code&gt;,返回key对应的value的从start到end的内容(包含start和end).&lt;/li&gt;
&lt;li&gt;如果key不存在的时候，返回的是空字符串.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ttl&#34;&gt;TTL&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法: &lt;code&gt;ttl key&lt;/code&gt;,得到key的超时时间.返回的单位为秒.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;不同返回值的含义&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; -1 -- 如果key没有超时时间,则返回-1.
 -2 -- 如果key不存在,返回-2.
 否则以秒为大内，返回key的超时剩余时间.
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;incr-decr-incrby-decrby&#34;&gt;INCR/DECR/INCRBY/DECRBY&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;用法 : &lt;code&gt;incr/decr key&lt;/code&gt;对key做加/减1.&lt;code&gt;incrby/decrby key incrementVal/decrementVal&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;如果 key 不存在，那么 key 的值会先被初始化为 0,然后再执行操作.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;strlen&#34;&gt;STRLEN&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;用法： &lt;code&gt;strlen key&lt;/code&gt;,返回一个string value的长度.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>excel export by poi</title>
      <link>http://littleworld.me/2016/07/31/excel-export-by-poi</link>
      <pubDate>Sun, 31 Jul 2016 20:54:41 +0800</pubDate>
      
      <guid>http://littleworld.me/2016/07/31/excel-export-by-poi</guid>
      <description>

&lt;p&gt;It&amp;rsquo;s a online optimization for Excel export which might be a common demand, I will demonstrate the resolve thoughts , concrete problems , abstraction and the final result in this post.&lt;/p&gt;

&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;Recently,I&amp;rsquo;ve been accepted a task from my boss about the excel export from our sites. The problem is summarized into two major problems as followed:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The download is slow.&lt;/li&gt;
&lt;li&gt;Sometimes it will cause the JVM to crash.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;process&#34;&gt;Process&lt;/h2&gt;

&lt;p&gt;After digging into the code ,I&amp;rsquo;ve found we used the &lt;code&gt;poi&lt;/code&gt; lib from &lt;code&gt;Apache&lt;/code&gt;, and there were some serious issues where were confronted with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;JPA query,As for the high-level abstracted ORM tools,that may be a common problem ,the domain-driven code for database query.which may result in too many database queries.bingo, that&amp;rsquo;s where we were.&lt;/li&gt;
&lt;li&gt;we used &lt;code&gt;XSSFWorkbook&lt;/code&gt; class to create the Excel sheet,which carried all the objects in memory that will cause &lt;code&gt;OOM&lt;/code&gt; when the excel is too large.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;concrete-problems&#34;&gt;Concrete Problems&lt;/h2&gt;

&lt;h3 id=&#34;sql&#34;&gt;SQL&lt;/h3&gt;

&lt;p&gt;As for JPA ,it is a wrapper of Hibernate which do generate all the SQL behind,you can reduce your focus on the business domain and logic.but sometimes it will not be a good choice to use it in a simple way.
for example,if there&amp;rsquo;s a table(table &lt;code&gt;A&lt;/code&gt;) in the database ,and a column as another table&amp;rsquo;s id(table &lt;code&gt;B&lt;/code&gt;). at the same time, you abstract the two into an Entity and a field. which can be expressed as followed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; class B{
    private A xxx
 }
 class A{
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in this way, the JPA will do the query sent from B as a sequence of :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 1. query from table B ,filter all the rows by relevant conditions.
 2. query from table A by id ,from the above queries result.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;for queries like this,small amount of query ,it will be acceptable.But when the queried rows from the 1st query reaches some quantity,the interaction between the application server and the database will cause performance problems.&lt;/p&gt;

&lt;h3 id=&#34;poi&#34;&gt;POI&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;POI&lt;/code&gt; is a mature lib from Apache. but for different demand ,there can be different implementations for excel generation.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HSSF , for the Excel &amp;lsquo;97(-2007) file format.&lt;/li&gt;
&lt;li&gt;XSSF,  for the Excel 2007 OOXML (.xlsx) file format ,which uses XML as the underground implementation as the excel archive.&lt;/li&gt;
&lt;li&gt;SXSSF, compatible with the XSSF,but SXSSF achieves its low memory footprint by limiting access to the rows that are within a sliding window, while XSSF gives access to all rows in the document. Older rows that are no longer in the window become inaccessible, as they are written to the disk.
apparently ,from the display above,we can draw a safe conclusion: ** we should use SXSSF **, because we didn&amp;rsquo;t know how much rows it will be generated by limited queries,we must limit the memory access for safety.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;resolve&#34;&gt;Resolve&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Replace all the ORM query with &lt;code&gt;native sql&lt;/code&gt; to accelerate the SQL query speed.which may not be that handy for ORM mapping tool.but as for speed, it is an overwhelming winner for &lt;code&gt;SQL&lt;/code&gt; to ORM.&lt;/li&gt;
&lt;li&gt;use the &lt;code&gt;SXSSWorkbook&lt;/code&gt; as an replacement for &lt;code&gt;XSSFWorkbook&lt;/code&gt; which will reduce the memory footprint dramatically.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;further-more&#34;&gt;Further More&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Isolate the excel server with other servers.As is known ,The excel process will generate a large amount of temp objects,which will affect the online performance that will result in latency of other online request. so Isolation is a good choice. Which can be down in some ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;configure universal URI for excels,then you can configure the PROXY at the NGINX layer to specified machines.&lt;/li&gt;
&lt;li&gt;configure a sub-domain,then as for the URL,you can write as &lt;code&gt;//subdomain/xxx&lt;/code&gt;(don&amp;rsquo;t touch the protocol,the browser will adapt it no matter it is http or https),you just modify the domain of the request URL. and configure the subdomain proxy at the NGINX.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;configure the Database query to a slave database instead of the master one, because the query may bring some pressure to the database that may cause the sync latency rising between master database and the slave ones and of course the performance problems which will affect other database operations.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;a little improvement by object sharing. for our export,there will be many Date object .I do some object sharing in the request by a &lt;code&gt;HashMap&lt;/code&gt;,I can get a formatted Date String by a &lt;code&gt;Get&lt;/code&gt; but not a &lt;code&gt;FastDateFormat&lt;/code&gt; which will be much faster and reduce the memory footprint.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;result&#34;&gt;Result&lt;/h2&gt;

&lt;p&gt;The Excel can be generated and exported into client in a short period. And with the isolation with other online servers,we can ignore the impact by the excel-export to our online business and the latency.&lt;/p&gt;

&lt;h2 id=&#34;tips&#34;&gt;Tips&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Don&amp;rsquo;t forget to invoke poi&amp;rsquo;s &lt;code&gt;dispose&lt;/code&gt; after the whole process. Otherwise,there will be a lot of temp files on your server.&lt;/li&gt;
&lt;li&gt;Prepare the excel header row in advance which is better for speed.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>RabbitMQ</title>
      <link>http://littleworld.me/2016/07/24/rabbitmq</link>
      <pubDate>Sun, 24 Jul 2016 14:20:41 +0800</pubDate>
      
      <guid>http://littleworld.me/2016/07/24/rabbitmq</guid>
      <description>

&lt;p&gt;Introduction and notes about the &lt;code&gt;AMQP&lt;/code&gt; product:RabbitMQ, which is a widely used messaging-queue product,Here I will show some concepts about it on this post.&lt;/p&gt;

&lt;h3 id=&#34;enable-web-interface-management&#34;&gt;enable web interface management&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;rabbitmq-plugins enable rabbitmq_management
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;messaging-model&#34;&gt;Messaging Model.&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;  //Simplify the Model
  - A producer is a user application that sends messages.
  - A queue is a buffer that stores messages.
  - A consumer is a user application that receives messages.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But Actually,The core idea in the messaging model in RabbitMQ is that the producer never sends any messages directly to a queue. Actually, quite often the producer doesn&amp;rsquo;t even know if a message will be delivered to any queue at all.Instead, the producer can only send messages to an exchange. An exchange is a very simple thing. On one side it receives messages from producers and the other side it pushes them to queues. The exchange must know exactly what to do with a message it receives. Should it be appended to a particular queue? Should it be appended to many queues? Or should it get discarded. The rules for that are defined by the exchange type.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;default exchange named &lt;code&gt;amq.direct&lt;/code&gt; is &lt;code&gt;direct&lt;/code&gt; type exchange, default exchange is very useful,because every queue that is created is automatically bound to it with a routing key which is the same as the queue name.So when we don&amp;rsquo;t declare a exchange,it will work well . the default direct exchange is ideal for the &lt;code&gt;unicast&lt;/code&gt; routing of messages.Direct exchanges are often used to distribute tasks between multiple workers in a &lt;code&gt;round-robin&lt;/code&gt; manner. When doing so, it is important to understand that, in AMQP 0-9-1, &lt;strong&gt;messages are load balanced between consumers and not between queues.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;exchange-types&#34;&gt;Exchange Types&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- direct,it can dispatch queues,the exchange will dispatch messages according to the `routing_key` matching,when a exchange is declared,a `routing_key` was defined,after queue binding,the `routing` between queues and exchange was established, when a message goes to the exchange,if the `routing_key` of a message matches the `routing_key` of the exchange,it will be dispatched to the queue,which declares the `routing_key` when it established the binding.

- topic,compared to `direct` type ,`topic` can route based on multiple criteria.

- headers, routing on message headers instead of `routing_key`, Headers exchanges ignore the routing key attribute.

- fanout, it just broadcasts all the messages it receives to all the queues it knows. It ignores that `routing_key` setting on the exchange setting,It just do **mindless broadcasting**.
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;message-publish&#34;&gt;Message Publish&lt;/h3&gt;

&lt;p&gt;when we do simple messaging things,we don&amp;rsquo;t need to specify the exchange,instead we use an empty string to denote  default or nameless exchange: messages are routed to the queue with the name specified by routing_key, if it exists.&lt;/p&gt;

&lt;p&gt;the exchanges existed can be queried by command like : &lt;code&gt;rabbitmqctl list_exchanges&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;bindings&#34;&gt;Bindings&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;tell the exchange to send messages to our queue. That relationship between exchange and a queue is called a binding.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rabbitmqctl list_bindings&lt;/code&gt; to list existing Bindings on the RabbitMQ server.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;durablity&#34;&gt;Durablity&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;queue of rabbitMQ was set durable,but after the RabbitMQ broker was restarted,the queue was empty.Because at the same time  you should set the property called  &lt;code&gt;DeliveryMode&lt;/code&gt; of the message to be &lt;code&gt;persistent&lt;/code&gt; too.
&lt;code&gt;DeliveryMode&lt;/code&gt; can be set as two values:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;1&lt;/code&gt; represents &lt;code&gt;transient&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;2&lt;/code&gt; represents &lt;code&gt;persistent&lt;/code&gt;,with that value the item will be persisted into disk storage instantly when the broker receives the publishing.
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;fair-dispatch&#34;&gt;Fair dispatch.&lt;/h3&gt;

&lt;p&gt;RabbitMQ just dispatches a message when the message enters the queue. It doesn&amp;rsquo;t look at the number of unacknowledged messages for a consumer. It just blindly dispatches every nth message to the nth consumer.In this context,sometimes, that we push messages evenly to every worker is not properly right.we could dispatch by each worker&amp;rsquo;s capacity,  we can use the &lt;code&gt;basic.qos&lt;/code&gt; method with the &lt;code&gt;prefetch_count=${number}&lt;/code&gt; setting. This tells RabbitMQ not to give more than one message to a worker at a time. Or, in other words, don&amp;rsquo;t dispatch a new message to a worker until it has processed and acknowledged the previous one. Instead, it will dispatch it to the next worker that is not still busy.(In a real world.the prefetch_count might be not only one for efficiency,but might not too much either).&lt;/p&gt;

&lt;h3 id=&#34;message-removal&#34;&gt;Message Removal&lt;/h3&gt;

&lt;p&gt;RabbitMQ will remove the messages from memory and queue of course,but if the  consumer dies (its channel is closed, connection is closed, or TCP connection is lost),we will lose all the messages that were dispatched to this particular worker but were not yet handled.
  we should not remove the message from RabbitMQ broker immediately after delivery success to the consumer. Instead the mechanism should be like this:
    1. the messages delivered to consumer,do not remove immediately but wait.
    2. the consumer do all the processing and do ACK to the RabbitMQ broker.
    3. If an ACK was received from the broker ,the message can be removed from broker now.&lt;/p&gt;

&lt;h1 id=&#34;links&#34;&gt;Links&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.rabbitmq.com/tutorials/amqp-concepts.html&#34;&gt;RabbitMQ concepts&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>